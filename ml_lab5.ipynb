{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanumeena28/ML-Assignment/blob/main/ml_lab5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target)\n",
        "\n",
        "# Function to train & evaluate with Linear Regression (forcing classification)\n",
        "def evaluate_model(X_train, X_val, y_train, y_val, method=\"Original\"):\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions will be continuous â†’ round to nearest integer\n",
        "    y_pred = np.rint(model.predict(X_val)).astype(int)\n",
        "\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    macro_f1 = f1_score(y_val, y_pred, average=\"macro\")\n",
        "    print(f\"\\n===== {method} =====\")\n",
        "    print(classification_report(y_val, y_pred))\n",
        "    return acc, macro_f1\n",
        "\n",
        "\n",
        "splits = [(0.8, 0.1, 0.1), (0.7, 0.15, 0.15)]\n",
        "results = []\n",
        "\n",
        "for train_size, val_size, test_size in splits:\n",
        "    print(f\"\\n=== Split: Train {int(train_size*100)}%, Val {int(val_size*100)}%, Test {int(test_size*100)}% ===\")\n",
        "\n",
        "\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X, y, train_size=train_size, stratify=y, random_state=42\n",
        "    )\n",
        "\n",
        "\n",
        "    relative_val = val_size / (val_size + test_size)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, train_size=relative_val, stratify=y_temp, random_state=42\n",
        "    )\n",
        "\n",
        "\n",
        "    acc, f1 = evaluate_model(X_train, X_val, y_train, y_val, method=\"Original\")\n",
        "    results.append((f\"{int(train_size*100)}-{int(val_size*100)}-{int(test_size*100)}\", \"Original\", acc, f1))\n",
        "\n",
        "\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_res, y_res = ros.fit_resample(X_train, y_train)\n",
        "    acc, f1 = evaluate_model(X_res, X_val, y_res, y_val, method=\"Random Oversampling\")\n",
        "    results.append((f\"{int(train_size*100)}-{int(val_size*100)}-{int(test_size*100)}\", \"RandomOversampling\", acc, f1))\n",
        "\n",
        "    # SMOTE\n",
        "    smote = SMOTE(random_state=42, k_neighbors=1)  # you can also try k=5\n",
        "    X_res, y_res = smote.fit_resample(X_train, y_train)\n",
        "    acc, f1 = evaluate_model(X_res, X_val, y_res, y_val, method=\"SMOTE\")\n",
        "    results.append((f\"{int(train_size*100)}-{int(val_size*100)}-{int(test_size*100)}\", \"SMOTE\", acc, f1))\n",
        "\n",
        "\n",
        "df_results = pd.DataFrame(results, columns=[\"Split\", \"Method\", \"Accuracy\", \"Macro_F1\"])\n",
        "print(\"\\n===== Final Comparison Table =====\")\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvlidM7zpvWo",
        "outputId": "1eac228a-60d8-4f0b-b1e9-bbd6489573f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Split: Train 80%, Val 10%, Test 10% ===\n",
            "\n",
            "===== Original =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "\n",
            "===== Random Oversampling =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "\n",
            "===== SMOTE =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        15\n",
            "   macro avg       1.00      1.00      1.00        15\n",
            "weighted avg       1.00      1.00      1.00        15\n",
            "\n",
            "\n",
            "=== Split: Train 70%, Val 15%, Test 15% ===\n",
            "\n",
            "===== Original =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       0.88      1.00      0.93         7\n",
            "           2       1.00      0.86      0.92         7\n",
            "\n",
            "    accuracy                           0.95        22\n",
            "   macro avg       0.96      0.95      0.95        22\n",
            "weighted avg       0.96      0.95      0.95        22\n",
            "\n",
            "\n",
            "===== Random Oversampling =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       0.88      1.00      0.93         7\n",
            "           2       1.00      0.86      0.92         7\n",
            "\n",
            "    accuracy                           0.95        22\n",
            "   macro avg       0.96      0.95      0.95        22\n",
            "weighted avg       0.96      0.95      0.95        22\n",
            "\n",
            "\n",
            "===== SMOTE =====\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       0.88      1.00      0.93         7\n",
            "           2       1.00      0.86      0.92         7\n",
            "\n",
            "    accuracy                           0.95        22\n",
            "   macro avg       0.96      0.95      0.95        22\n",
            "weighted avg       0.96      0.95      0.95        22\n",
            "\n",
            "\n",
            "===== Final Comparison Table =====\n",
            "      Split              Method  Accuracy  Macro_F1\n",
            "0  80-10-10            Original  1.000000  1.000000\n",
            "1  80-10-10  RandomOversampling  1.000000  1.000000\n",
            "2  80-10-10               SMOTE  1.000000  1.000000\n",
            "3  70-15-15            Original  0.954545  0.952137\n",
            "4  70-15-15  RandomOversampling  0.954545  0.952137\n",
            "5  70-15-15               SMOTE  0.954545  0.952137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sfyerUMd9cE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"Iris.csv\")\n",
        "\n",
        "# Features and labels\n",
        "X = df.drop(columns=[\"Species\", \"Id\"])\n",
        "y = df[\"Species\"]\n",
        "\n",
        "# Encode labels to numeric\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "7t9iyboxgr4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "4Z33uHKOgxsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train class distribution:\\n\", pd.Series(y_train).value_counts(normalize=True))\n",
        "print(\"Validation class distribution:\\n\", pd.Series(y_val).value_counts(normalize=True))\n",
        "print(\"Test class distribution:\\n\", pd.Series(y_test).value_counts(normalize=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRBibuz8g7rF",
        "outputId": "15910d97-6918-447f-a31f-3b115a1dab49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train class distribution:\n",
            " 0    0.333333\n",
            "2    0.333333\n",
            "1    0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Validation class distribution:\n",
            " 0    0.333333\n",
            "2    0.333333\n",
            "1    0.333333\n",
            "Name: proportion, dtype: float64\n",
            "Test class distribution:\n",
            " 0    0.333333\n",
            "1    0.333333\n",
            "2    0.333333\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Validate\n",
        "y_pred_val = model.predict(X_val)\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred_val))\n",
        "print(classification_report(y_val, y_pred_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYZC51EihIRs",
        "outputId": "c42ba1d8-d296-4643-ed06-a0730d4c556b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      0.80      0.89         5\n",
            "           2       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.94      0.93      0.93        15\n",
            "weighted avg       0.94      0.93      0.93        15\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Always reset index so X and y indices match\n",
        "X_train_imbalanced = X_train_imbalanced.reset_index(drop=True)\n",
        "y_train_imbalanced = y_train_imbalanced.reset_index(drop=True)\n",
        "\n",
        "# Select samples from class 0\n",
        "mask = (y_train_imbalanced == 0)\n",
        "drop_idx = y_train_imbalanced[mask].sample(15, random_state=42).index\n",
        "\n",
        "# Drop those indices\n",
        "X_train_imbalanced = X_train_imbalanced.drop(drop_idx)\n",
        "y_train_imbalanced = y_train_imbalanced.drop(drop_idx)\n",
        "\n",
        "print(\"Class distribution before oversampling:\\n\", y_train_imbalanced.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8VED-I4jUPU",
        "outputId": "aa261dde-98b4-4bd9-ae33-356dbc76c6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before oversampling:\n",
            " 2    40\n",
            "1    40\n",
            "0    25\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import pandas as pd\n",
        "\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X_resampled, y_resampled = ros.fit_resample(X_train_imbalanced, y_train_imbalanced)\n",
        "\n",
        "print(\"After Random Oversampling:\\n\", pd.Series(y_resampled).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze8MBLvRjt7R",
        "outputId": "af82eb2f-878b-4f1b-bd44-75be06cf5338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After Random Oversampling:\n",
            " 0    40\n",
            "2    40\n",
            "1    40\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_smote, y_smote = smote.fit_resample(X_train_imbalanced, y_train_imbalanced)\n",
        "\n",
        "print(\"After SMOTE:\\n\", pd.Series(y_smote).value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmc1p1zXjxDV",
        "outputId": "b9cffa9e-d054-44ef-f798-726350a838ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After SMOTE:\n",
            " 0    40\n",
            "2    40\n",
            "1    40\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Train on RandomOversampler output\n",
        "model_ros = LogisticRegression(max_iter=200)\n",
        "model_ros.fit(X_resampled, y_resampled)\n",
        "\n",
        "y_pred_ros = model_ros.predict(X_val)\n",
        "print(\"Validation Accuracy (Random Oversampling):\", accuracy_score(y_val, y_pred_ros))\n",
        "print(classification_report(y_val, y_pred_ros))\n",
        "\n",
        "# Train on SMOTE output\n",
        "model_smote = LogisticRegression(max_iter=200)\n",
        "model_smote.fit(X_smote, y_smote)\n",
        "\n",
        "y_pred_smote = model_smote.predict(X_val)\n",
        "print(\"Validation Accuracy (SMOTE):\", accuracy_score(y_val, y_pred_smote))\n",
        "print(classification_report(y_val, y_pred_smote))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1IYpmBDjzsw",
        "outputId": "695bd9fb-8013-46d3-ff51-0723173486be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy (Random Oversampling): 0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      0.80      0.89         5\n",
            "           2       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.94      0.93      0.93        15\n",
            "weighted avg       0.94      0.93      0.93        15\n",
            "\n",
            "Validation Accuracy (SMOTE): 0.9333333333333333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      0.80      0.89         5\n",
            "           2       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.93        15\n",
            "   macro avg       0.94      0.93      0.93        15\n",
            "weighted avg       0.94      0.93      0.93        15\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Always reset index so X and y indices match\n",
        "X_train_imbalanced = X_train_imbalanced.reset_index(drop=True)\n",
        "y_train_imbalanced = y_train_imbalanced.reset_index(drop=True)\n",
        "\n",
        "# Select samples from class 0\n",
        "mask = (y_train_imbalanced == 1)\n",
        "drop_idx = y_train_imbalanced[mask].sample(15, random_state=42).index\n",
        "\n",
        "# Drop those indices\n",
        "X_train_imbalanced = X_train_imbalanced.drop(drop_idx)\n",
        "y_train_imbalanced = y_train_imbalanced.drop(drop_idx)\n",
        "\n",
        "print(\"Class distribution before oversampling:\\n\", y_train_imbalanced.value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owQ2NqWHkChy",
        "outputId": "a9a2afd9-0026-4c73-e324-fd47569ae4a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before oversampling:\n",
            " 2    40\n",
            "0    25\n",
            "1    25\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "\n",
        "# 1. Load dataset\n",
        "df = pd.read_csv(\"Iris.csv\")\n",
        "X = df.drop(columns=[\"Species\", \"Id\"])\n",
        "y = df[\"Species\"]\n",
        "\n",
        "# Encode labels\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Stratified split 80/10/10\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
        ")\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# 2. Run experiment for each class being undersampled\n",
        "for cls in np.unique(y_train):\n",
        "    print(f\"\\n===== Experiment: Undersample Class {cls} =====\")\n",
        "\n",
        "    # Convert to DataFrame/Series with aligned indices\n",
        "    X_train_df = pd.DataFrame(X_train, columns=X.columns).reset_index(drop=True)\n",
        "    y_train_df = pd.Series(y_train).reset_index(drop=True)\n",
        "\n",
        "    # Remove 15 samples from this class\n",
        "    mask = (y_train_df == cls)\n",
        "    drop_idx = y_train_df[mask].sample(15, random_state=42).index\n",
        "    X_train_imb = X_train_df.drop(drop_idx).reset_index(drop=True)\n",
        "    y_train_imb = y_train_df.drop(drop_idx).reset_index(drop=True)\n",
        "\n",
        "    print(\"Class distribution before oversampling:\\n\", y_train_imb.value_counts())\n",
        "\n",
        "    # 2a. Random Oversampling\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_ros, y_ros = ros.fit_resample(X_train_imb, y_train_imb)\n",
        "\n",
        "    model_ros = LogisticRegression(max_iter=200)\n",
        "    model_ros.fit(X_ros, y_ros)\n",
        "    y_pred_ros = model_ros.predict(X_val)\n",
        "    acc_ros = accuracy_score(y_val, y_pred_ros)\n",
        "    report_ros = classification_report(y_val, y_pred_ros, output_dict=True)\n",
        "\n",
        "    results.append({\n",
        "        \"Minority_Class\": cls,\n",
        "        \"Method\": \"Random Oversampling\",\n",
        "        \"Accuracy\": acc_ros,\n",
        "        \"Macro_F1\": report_ros[\"macro avg\"][\"f1-score\"]\n",
        "    })\n",
        "\n",
        "    # 2b. SMOTE\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_smote, y_smote = smote.fit_resample(X_train_imb, y_train_imb)\n",
        "\n",
        "    model_smote = LogisticRegression(max_iter=200)\n",
        "    model_smote.fit(X_smote, y_smote)\n",
        "    y_pred_smote = model_smote.predict(X_val)\n",
        "    acc_smote = accuracy_score(y_val, y_pred_smote)\n",
        "    report_smote = classification_report(y_val, y_pred_smote, output_dict=True)\n",
        "\n",
        "    results.append({\n",
        "        \"Minority_Class\": cls,\n",
        "        \"Method\": \"SMOTE\",\n",
        "        \"Accuracy\": acc_smote,\n",
        "        \"Macro_F1\": report_smote[\"macro avg\"][\"f1-score\"]\n",
        "    })\n",
        "\n",
        "# 3. Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"\\n===== Final Comparison Table =====\\n\")\n",
        "print(results_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcqwqFh7kZym",
        "outputId": "25138fdf-69bf-4669-edf3-b8c5a831dd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Experiment: Undersample Class 0 =====\n",
            "Class distribution before oversampling:\n",
            " 2    40\n",
            "1    40\n",
            "0    25\n",
            "Name: count, dtype: int64\n",
            "\n",
            "===== Experiment: Undersample Class 1 =====\n",
            "Class distribution before oversampling:\n",
            " 0    40\n",
            "2    40\n",
            "1    25\n",
            "Name: count, dtype: int64\n",
            "\n",
            "===== Experiment: Undersample Class 2 =====\n",
            "Class distribution before oversampling:\n",
            " 0    40\n",
            "1    40\n",
            "2    25\n",
            "Name: count, dtype: int64\n",
            "\n",
            "===== Final Comparison Table =====\n",
            "\n",
            "   Minority_Class               Method  Accuracy  Macro_F1\n",
            "0               0  Random Oversampling  0.933333   0.93266\n",
            "1               0                SMOTE  0.933333   0.93266\n",
            "2               1  Random Oversampling  0.933333   0.93266\n",
            "3               1                SMOTE  0.933333   0.93266\n",
            "4               2  Random Oversampling  1.000000   1.00000\n",
            "5               2                SMOTE  1.000000   1.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== Iris: Linear Regression + Oversampling/SMOTE Experiments ====\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
        "\n",
        "# ----------------- Helpers -----------------\n",
        "def stratified_split(X, y, train_p, val_p, test_p, seed=42):\n",
        "    assert abs(train_p + val_p + test_p - 1.0) < 1e-9\n",
        "    # First: train vs temp\n",
        "    X_tr, X_tmp, y_tr, y_tmp = train_test_split(\n",
        "        X, y, test_size=(1 - train_p), stratify=y, random_state=seed\n",
        "    )\n",
        "    # Then: temp -> val & test\n",
        "    val_share_of_tmp = val_p / (val_p + test_p)  # split temp into val/test\n",
        "    X_val, X_te, y_val, y_te = train_test_split(\n",
        "        X_tmp, y_tmp, test_size=(1 - val_share_of_tmp), stratify=y_tmp, random_state=seed\n",
        "    )\n",
        "    return X_tr, X_val, X_te, y_tr, y_val, y_te\n",
        "\n",
        "def make_imbalance_drop(X_tr, y_tr, minority_cls, n_drop, seed=42):\n",
        "    \"\"\"Drop n_drop rows of the chosen class from the training set (keeps indices aligned).\"\"\"\n",
        "    X_df = pd.DataFrame(X_tr, columns=X.columns).reset_index(drop=True)\n",
        "    y_sr = pd.Series(y_tr).reset_index(drop=True)\n",
        "\n",
        "    idx_pool = y_sr[y_sr == minority_cls].index\n",
        "    n_drop = min(n_drop, len(idx_pool) - 1)  # keep at least 1 sample\n",
        "    drop_idx = idx_pool.to_series().sample(n_drop, random_state=seed).index\n",
        "\n",
        "    X_imb = X_df.drop(drop_idx).reset_index(drop=True)\n",
        "    y_imb = y_sr.drop(drop_idx).reset_index(drop=True)\n",
        "    return X_imb, y_imb\n",
        "\n",
        "def train_eval_linear_ovr(X_tr, y_tr, X_eval, y_eval):\n",
        "    \"\"\"\n",
        "    Linear Regression used as a classifier:\n",
        "      - one-hot encode y\n",
        "      - fit multi-output LinearRegression\n",
        "      - predict scores and argmax to class labels\n",
        "    \"\"\"\n",
        "    ohe = OneHotEncoder(sparse_output=False)\n",
        "    Y_tr = ohe.fit_transform(np.array(y_tr).reshape(-1, 1))  # (n, n_classes)\n",
        "\n",
        "    lin = LinearRegression()\n",
        "    lin.fit(X_tr, Y_tr)\n",
        "    scores = lin.predict(X_eval)  # (m, n_classes)\n",
        "    y_pred = scores.argmax(axis=1)\n",
        "\n",
        "    acc = accuracy_score(y_eval, y_pred)\n",
        "    macro_f1 = f1_score(y_eval, y_pred, average=\"macro\")\n",
        "    report = classification_report(y_eval, y_pred, zero_division=0)\n",
        "    return acc, macro_f1, report\n",
        "\n",
        "def run_block(X_tr, y_tr, X_val, y_val, minority_cls, title, sampler):\n",
        "    \"\"\"Fit sampler on *training only*, then train/evaluate Linear OVR on validation.\"\"\"\n",
        "    X_bal, y_bal = sampler.fit_resample(X_tr, y_tr)\n",
        "    acc, macro_f1, report = train_eval_linear_ovr(X_bal, y_bal, X_val, y_val)\n",
        "    row = {\n",
        "        \"Minority_Class\": minority_cls,\n",
        "        \"Method\": title,\n",
        "        \"Val_Accuracy\": acc,\n",
        "        \"Val_MacroF1\": macro_f1,\n",
        "    }\n",
        "    return row, report\n",
        "\n",
        "# ----------------- Load & Encode -----------------\n",
        "df = pd.read_csv(\"Iris.csv\")\n",
        "X = df.drop(columns=[\"Species\", \"Id\"])\n",
        "y = LabelEncoder().fit_transform(df[\"Species\"])  # 0,1,2\n",
        "\n",
        "# ----------------- Experiment Settings -----------------\n",
        "split_schemes = [\n",
        "    (0.80, 0.10, 0.10, \"80/10/10\"),\n",
        "    (0.70, 0.15, 0.15, \"70/15/15\"),\n",
        "]\n",
        "minority_drop = 15  # how many to remove from the chosen class in the training split\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for train_p, val_p, test_p, tag in split_schemes:\n",
        "    print(f\"\\n================= Split Scheme: {tag} =================\")\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = stratified_split(\n",
        "        X, y, train_p, val_p, test_p, seed=42\n",
        "    )\n",
        "\n",
        "    # Baseline (no imbalance, no oversampling) with Linear Regression classifier\n",
        "    base_acc, base_f1, base_report = train_eval_linear_ovr(X_train, y_train, X_val, y_val)\n",
        "    print(\"\\n--- Baseline (No Imbalance) on Validation ---\")\n",
        "    print(base_report)\n",
        "    all_results.append({\n",
        "        \"Split\": tag, \"Minority_Class\": \"None\", \"Method\": \"Baseline (Linear OVR)\",\n",
        "        \"Val_Accuracy\": base_acc, \"Val_MacroF1\": base_f1\n",
        "    })\n",
        "\n",
        "    # Run for each class as minority\n",
        "    for cls in np.unique(y_train):\n",
        "        # Create imbalance by dropping samples from this class\n",
        "        X_imb, y_imb = make_imbalance_drop(X_train, y_train, minority_cls=cls, n_drop=minority_drop, seed=42)\n",
        "\n",
        "        print(f\"\\n--- Class distribution after dropping from class {cls} (train only) ---\")\n",
        "        print(pd.Series(y_imb).value_counts())\n",
        "\n",
        "        # 1) Random Oversampling\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        row, report = run_block(X_imb, y_imb, X_val, y_val, cls, \"Random Oversampling\", ros)\n",
        "        print(\"\\nRandom Oversampling (Validation Report):\\n\", report)\n",
        "        row.update({\"Split\": tag})\n",
        "        all_results.append(row)\n",
        "\n",
        "        # 2) SMOTE Setting (a): \"Take any 2 samples\" â†’ approximate via k_neighbors=2\n",
        "        smote_two = SMOTE(random_state=42, k_neighbors=2)\n",
        "        row, report = run_block(X_imb, y_imb, X_val, y_val, cls, \"SMOTE (k_neighbors=2)\", smote_two)\n",
        "        print(\"\\nSMOTE k=2 (Validation Report):\\n\", report)\n",
        "        row.update({\"Split\": tag})\n",
        "        all_results.append(row)\n",
        "\n",
        "        # 3) SMOTE Setting (b): \"Nearest sample\" â†’ k_neighbors=1\n",
        "        smote_one = SMOTE(random_state=42, k_neighbors=1)\n",
        "        row, report = run_block(X_imb, y_imb, X_val, y_val, cls, \"SMOTE (k_neighbors=1, nearest)\", smote_one)\n",
        "        print(\"\\nSMOTE k=1 (nearest) (Validation Report):\\n\", report)\n",
        "        row.update({\"Split\": tag})\n",
        "        all_results.append(row)\n",
        "\n",
        "# ----------------- Final Tables -----------------\n",
        "results_df = pd.DataFrame(all_results)\n",
        "print(\"\\n================= FINAL COMPARISON (Validation) =================\")\n",
        "print(results_df.sort_values([\"Split\", \"Minority_Class\", \"Method\"]).reset_index(drop=True))\n",
        "\n",
        "# (Optional) Also evaluate the best model(s) on the untouched test set.\n",
        "# You can re-train on the *oversampled training data* and then predict on X_test similarly.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "col0yvYgloDG",
        "outputId": "8fb92ee8-9d4d-4581-a4ea-66aacc8318a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================= Split Scheme: 80/10/10 =================\n",
            "\n",
            "--- Baseline (No Imbalance) on Validation ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.80        15\n",
            "   macro avg       0.81      0.80      0.80        15\n",
            "weighted avg       0.81      0.80      0.80        15\n",
            "\n",
            "\n",
            "--- Class distribution after dropping from class 0 (train only) ---\n",
            "2    40\n",
            "1    40\n",
            "0    25\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Random Oversampling (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.80        15\n",
            "   macro avg       0.81      0.80      0.80        15\n",
            "weighted avg       0.81      0.80      0.80        15\n",
            "\n",
            "\n",
            "SMOTE k=2 (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.80        15\n",
            "   macro avg       0.81      0.80      0.80        15\n",
            "weighted avg       0.81      0.80      0.80        15\n",
            "\n",
            "\n",
            "SMOTE k=1 (nearest) (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.80        15\n",
            "   macro avg       0.81      0.80      0.80        15\n",
            "weighted avg       0.81      0.80      0.80        15\n",
            "\n",
            "\n",
            "--- Class distribution after dropping from class 1 (train only) ---\n",
            "0    40\n",
            "2    40\n",
            "1    25\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Random Oversampling (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.80        15\n",
            "   macro avg       0.81      0.80      0.80        15\n",
            "weighted avg       0.81      0.80      0.80        15\n",
            "\n",
            "\n",
            "SMOTE k=2 (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.80        15\n",
            "   macro avg       0.81      0.80      0.80        15\n",
            "weighted avg       0.81      0.80      0.80        15\n",
            "\n",
            "\n",
            "SMOTE k=1 (nearest) (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.80        15\n",
            "   macro avg       0.81      0.80      0.80        15\n",
            "weighted avg       0.81      0.80      0.80        15\n",
            "\n",
            "\n",
            "--- Class distribution after dropping from class 2 (train only) ---\n",
            "0    40\n",
            "1    40\n",
            "2    25\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Random Oversampling (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.80      0.80      0.80         5\n",
            "           2       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.87        15\n",
            "   macro avg       0.87      0.87      0.87        15\n",
            "weighted avg       0.87      0.87      0.87        15\n",
            "\n",
            "\n",
            "SMOTE k=2 (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.75      0.60      0.67         5\n",
            "           2       0.67      0.80      0.73         5\n",
            "\n",
            "    accuracy                           0.80        15\n",
            "   macro avg       0.81      0.80      0.80        15\n",
            "weighted avg       0.81      0.80      0.80        15\n",
            "\n",
            "\n",
            "SMOTE k=1 (nearest) (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       0.80      0.80      0.80         5\n",
            "           2       0.80      0.80      0.80         5\n",
            "\n",
            "    accuracy                           0.87        15\n",
            "   macro avg       0.87      0.87      0.87        15\n",
            "weighted avg       0.87      0.87      0.87        15\n",
            "\n",
            "\n",
            "================= Split Scheme: 70/15/15 =================\n",
            "\n",
            "--- Baseline (No Imbalance) on Validation ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.62      0.62      0.62         8\n",
            "           2       0.62      0.62      0.62         8\n",
            "\n",
            "    accuracy                           0.74        23\n",
            "   macro avg       0.75      0.75      0.75        23\n",
            "weighted avg       0.74      0.74      0.74        23\n",
            "\n",
            "\n",
            "--- Class distribution after dropping from class 0 (train only) ---\n",
            "1    35\n",
            "2    34\n",
            "0    20\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Random Oversampling (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.71      0.62      0.67         8\n",
            "           2       0.67      0.75      0.71         8\n",
            "\n",
            "    accuracy                           0.78        23\n",
            "   macro avg       0.79      0.79      0.79        23\n",
            "weighted avg       0.78      0.78      0.78        23\n",
            "\n",
            "\n",
            "SMOTE k=2 (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.62      0.62      0.62         8\n",
            "           2       0.62      0.62      0.62         8\n",
            "\n",
            "    accuracy                           0.74        23\n",
            "   macro avg       0.75      0.75      0.75        23\n",
            "weighted avg       0.74      0.74      0.74        23\n",
            "\n",
            "\n",
            "SMOTE k=1 (nearest) (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.62      0.62      0.62         8\n",
            "           2       0.62      0.62      0.62         8\n",
            "\n",
            "    accuracy                           0.74        23\n",
            "   macro avg       0.75      0.75      0.75        23\n",
            "weighted avg       0.74      0.74      0.74        23\n",
            "\n",
            "\n",
            "--- Class distribution after dropping from class 1 (train only) ---\n",
            "0    35\n",
            "2    34\n",
            "1    20\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Random Oversampling (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.60      0.75      0.67         8\n",
            "           2       0.67      0.50      0.57         8\n",
            "\n",
            "    accuracy                           0.74        23\n",
            "   macro avg       0.76      0.75      0.75        23\n",
            "weighted avg       0.74      0.74      0.73        23\n",
            "\n",
            "\n",
            "SMOTE k=2 (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.60      0.75      0.67         8\n",
            "           2       0.67      0.50      0.57         8\n",
            "\n",
            "    accuracy                           0.74        23\n",
            "   macro avg       0.76      0.75      0.75        23\n",
            "weighted avg       0.74      0.74      0.73        23\n",
            "\n",
            "\n",
            "SMOTE k=1 (nearest) (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.60      0.75      0.67         8\n",
            "           2       0.67      0.50      0.57         8\n",
            "\n",
            "    accuracy                           0.74        23\n",
            "   macro avg       0.76      0.75      0.75        23\n",
            "weighted avg       0.74      0.74      0.73        23\n",
            "\n",
            "\n",
            "--- Class distribution after dropping from class 2 (train only) ---\n",
            "1    35\n",
            "0    35\n",
            "2    19\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Random Oversampling (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.62      0.62      0.62         8\n",
            "           2       0.62      0.62      0.62         8\n",
            "\n",
            "    accuracy                           0.74        23\n",
            "   macro avg       0.75      0.75      0.75        23\n",
            "weighted avg       0.74      0.74      0.74        23\n",
            "\n",
            "\n",
            "SMOTE k=2 (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.71      0.62      0.67         8\n",
            "           2       0.67      0.75      0.71         8\n",
            "\n",
            "    accuracy                           0.78        23\n",
            "   macro avg       0.79      0.79      0.79        23\n",
            "weighted avg       0.78      0.78      0.78        23\n",
            "\n",
            "\n",
            "SMOTE k=1 (nearest) (Validation Report):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         7\n",
            "           1       0.62      0.62      0.62         8\n",
            "           2       0.62      0.62      0.62         8\n",
            "\n",
            "    accuracy                           0.74        23\n",
            "   macro avg       0.75      0.75      0.75        23\n",
            "weighted avg       0.74      0.74      0.74        23\n",
            "\n",
            "\n",
            "================= FINAL COMPARISON (Validation) =================\n",
            "       Split Minority_Class                          Method  Val_Accuracy  \\\n",
            "0   70/15/15              0             Random Oversampling      0.782609   \n",
            "1   70/15/15              0  SMOTE (k_neighbors=1, nearest)      0.739130   \n",
            "2   70/15/15              0           SMOTE (k_neighbors=2)      0.739130   \n",
            "3   70/15/15              1             Random Oversampling      0.739130   \n",
            "4   70/15/15              1  SMOTE (k_neighbors=1, nearest)      0.739130   \n",
            "5   70/15/15              1           SMOTE (k_neighbors=2)      0.739130   \n",
            "6   70/15/15              2             Random Oversampling      0.739130   \n",
            "7   70/15/15              2  SMOTE (k_neighbors=1, nearest)      0.739130   \n",
            "8   70/15/15              2           SMOTE (k_neighbors=2)      0.782609   \n",
            "9   70/15/15           None           Baseline (Linear OVR)      0.739130   \n",
            "10  80/10/10              0             Random Oversampling      0.800000   \n",
            "11  80/10/10              0  SMOTE (k_neighbors=1, nearest)      0.800000   \n",
            "12  80/10/10              0           SMOTE (k_neighbors=2)      0.800000   \n",
            "13  80/10/10              1             Random Oversampling      0.800000   \n",
            "14  80/10/10              1  SMOTE (k_neighbors=1, nearest)      0.800000   \n",
            "15  80/10/10              1           SMOTE (k_neighbors=2)      0.800000   \n",
            "16  80/10/10              2             Random Oversampling      0.866667   \n",
            "17  80/10/10              2  SMOTE (k_neighbors=1, nearest)      0.866667   \n",
            "18  80/10/10              2           SMOTE (k_neighbors=2)      0.800000   \n",
            "19  80/10/10           None           Baseline (Linear OVR)      0.800000   \n",
            "\n",
            "    Val_MacroF1  \n",
            "0      0.790850  \n",
            "1      0.750000  \n",
            "2      0.750000  \n",
            "3      0.746032  \n",
            "4      0.746032  \n",
            "5      0.746032  \n",
            "6      0.750000  \n",
            "7      0.750000  \n",
            "8      0.790850  \n",
            "9      0.750000  \n",
            "10     0.797980  \n",
            "11     0.797980  \n",
            "12     0.797980  \n",
            "13     0.797980  \n",
            "14     0.797980  \n",
            "15     0.797980  \n",
            "16     0.866667  \n",
            "17     0.866667  \n",
            "18     0.797980  \n",
            "19     0.797980  \n"
          ]
        }
      ]
    }
  ]
}